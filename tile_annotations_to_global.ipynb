{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6105cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "via_annotations_file = \"D:/FCAT/annotations/tiles2_VIA_annotations_800_313.csv\"\n",
    "tiling_scheme_file = \"D:/FCAT/tiles2/tiling_scheme.json\"\n",
    "output_dir = \"D:/FCAT/annotations/\"\n",
    "rasterfile = \"D:/FCAT/FCAT2APPK.tif\"\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5e3f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function imports necessary metadata from the tiling scheme file generated during the earlier tiling script\n",
    "def import_tiling_scheme(tiling_scheme_file):\n",
    "    import json\n",
    "    from affine import Affine\n",
    "    \n",
    "    with open(tiling_scheme_file) as f:\n",
    "        tiling_scheme = json.load(f)\n",
    "    gt = tiling_scheme[\"transform\"]\n",
    "    geotransform = (gt[2], gt[0], gt[1], gt[5], gt[3], gt[4])\n",
    "    geotransform = Affine.from_gdal(*geotransform)\n",
    "    tiling_scheme[\"transform\"] = geotransform\n",
    "    return tiling_scheme\n",
    "\n",
    "tiling_scheme = import_tiling_scheme(tiling_scheme_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc1f7deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'box': [(682, 337), (800, 337), (800, 598), (682, 598)], 'class': 'Bottlebrush unk.', 'tile_ID': 'FCAT2APPK---69.png'}, {'box': [(195, 337), (457, 337), (457, 598), (195, 598)], 'class': 'Bottlebrush unk.', 'tile_ID': 'FCAT2APPK---70.png'}, {'box': [(324, 427), (587, 427), (587, 688), (324, 688)], 'class': 'Bottlebrush unk.', 'tile_ID': 'FCAT2APPK---70.png'}, {'box': [(446, 454), (708, 454), (708, 715), (446, 715)], 'class': 'Bottlebrush unk.', 'tile_ID': 'FCAT2APPK---70.png'}, {'box': [(720, 548), (800, 548), (800, 800), (720, 800)], 'class': 'Bottlebrush unk.', 'tile_ID': 'FCAT2APPK---70.png'}]\n"
     ]
    }
   ],
   "source": [
    "### This section converts a VIA file into generic tile format containing: box, class, tile filename\n",
    "### If you are using a different annotation format (coco, yolo, etc.) you will probably need your own\n",
    "### parsing function to convert that into the format that subsequent functions accept\n",
    "### (see \"new_row\" line below for desired output format)\n",
    "\n",
    "def VIA_to_generic_tiles(via_annotations_file):\n",
    "    import csv, json\n",
    "    via_annotations_list = []\n",
    "\n",
    "    # read each line, parse it, convert it, put it all back together\n",
    "    # then drop it in the appropriate subset\n",
    "    with open(via_annotations_file, \"r\") as f:\n",
    "        reader = csv.reader(f, delimiter=\",\")\n",
    "        for line in reader: \n",
    "            # skip empty line\n",
    "            if not line[5]:\n",
    "                continue\n",
    "            if '{}' in line[5]:\n",
    "                continue\n",
    "\n",
    "            if 'filename' in line[0]:\n",
    "                continue\n",
    "\n",
    "            filename = line[0]\n",
    "\n",
    "            # pulling from column named \"region_shape_attributes\"\n",
    "            box_entry = json.loads(line[5])\n",
    "            top_left_x, top_left_y, width, height = box_entry[\"x\"], box_entry[\"y\"], box_entry[\"width\"], box_entry[\"height\"]\n",
    "            if width == 0 or height == 0:\n",
    "                continue\n",
    "                # skip tiny/empty boxes\n",
    "\n",
    "            # convert from \"top left and width/height\" to \"x and y values at each corner of the box\"\n",
    "            if top_left_x < 0: top_left_x = 1\n",
    "            if top_left_y < 0: top_left_y = 1\n",
    "            x1, x2, y1, y2 = top_left_x, top_left_x + width, top_left_y, top_left_y + height \n",
    "\n",
    "            # pulling from column named \"region_attributes\" to get class names\n",
    "            class_name = next(iter(json.loads(line[6]).values()))\n",
    "\n",
    "            # skip unknown class, in this case. Might be useful in other applications though, e.g. total count\n",
    "            if class_name == \"Unknown\":\n",
    "                continue\n",
    "\n",
    "            # create the annotation row\n",
    "            new_row = {'box': [(x1,y1), (x2,y1), (x2,y2), (x1,y2)], 'class': class_name, 'tile_ID': filename}\n",
    "\n",
    "            # append the row to the our list\n",
    "            via_annotations_list.append(new_row)\n",
    "\n",
    "    return via_annotations_list\n",
    "\n",
    "generic_tiles =  VIA_to_generic_tiles(via_annotations_file)\n",
    "print(generic_tiles[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec20e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'box': [4578, 824, 4696, 1085],\n",
      "  'class': 'Bottlebrush unk.',\n",
      "  'tile_ID': 'FCAT2APPK---69.png'},\n",
      " {'box': [4578, 824, 4840, 1085],\n",
      "  'class': 'Bottlebrush unk.',\n",
      "  'tile_ID': 'FCAT2APPK---70.png'},\n",
      " {'box': [4707, 914, 4970, 1175],\n",
      "  'class': 'Bottlebrush unk.',\n",
      "  'tile_ID': 'FCAT2APPK---70.png'},\n",
      " {'box': [4829, 941, 5091, 1202],\n",
      "  'class': 'Bottlebrush unk.',\n",
      "  'tile_ID': 'FCAT2APPK---70.png'},\n",
      " {'box': [5103, 1035, 5183, 1287],\n",
      "  'class': 'Bottlebrush unk.',\n",
      "  'tile_ID': 'FCAT2APPK---70.png'}]\n"
     ]
    }
   ],
   "source": [
    "### This section converts tile annotations to orthomosaic annotations\n",
    "### then reduces the bounding box format to a more efficient x1y1, x2y2 format\n",
    "### which is the format we use for the non-max suppression functions\n",
    "\n",
    "import copy\n",
    "def tile_annotations_to_ortho(generic_tiles):\n",
    "    ortho_tiles = copy.deepcopy(generic_tiles)\n",
    "    for k, i in enumerate(ortho_tiles):\n",
    "        bounding_box = np.array(i['box'])\n",
    "        # update the new coordinates format from local tile coordinates to orthomosaic coordinates\n",
    "        bounding_box = bounding_box + [tiling_scheme['tile_pointers'][\"image_locations\"][i['tile_ID']]]\n",
    "        ortho_tiles[k]['box'] = bounding_box.tolist()\n",
    "    return(ortho_tiles)\n",
    "ortho_annotations = tile_annotations_to_ortho(generic_tiles)\n",
    "\n",
    "def pairs_to_xyxy(annotations):\n",
    "    for k, i in enumerate(annotations):\n",
    "        x_coordinates, y_coordinates = zip(*i['box'])\n",
    "        x1 = min(x_coordinates)\n",
    "        y1 = min(y_coordinates)\n",
    "        x2 = max(x_coordinates)\n",
    "        y2 = max(y_coordinates)\n",
    "        # convert our bounding box from coordinates format back to x1/y1/x2/y2 format\n",
    "        annotations[k]['box'] = [min(x_coordinates), min(y_coordinates), max(x_coordinates), max(y_coordinates)]\n",
    "    return annotations\n",
    "ortho_annotations = pairs_to_xyxy(ortho_annotations)\n",
    "pprint(ortho_annotations[0:5])\n",
    "\n",
    "### at this point we've converted our tile annotations to orthomosaic annotations, but there are likely redundancies\n",
    "### especially if there is overlap between tiles. We'll need to use non-maximum supppression or a comparable algorithm\n",
    "### to eliminate most/all of these redundancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39768404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts before NMS\n",
      "Fan unk.: 324/10208\n",
      "Oenocarpus bataua: 80/10208\n",
      "Astrocaryum standleyanum: 8/10208\n",
      "Attalea colenda: 12/10208\n",
      "Palm unk.: 180/10208\n",
      "Socratea exorrhiza: 76/10208\n",
      "Iriartea deltoidea: 576/10208\n",
      "Bottlebrush unk.: 8952/10208\n"
     ]
    }
   ],
   "source": [
    "print(f'Counts before NMS')\n",
    "for cl in list(set([i['class'] for i in ortho_annotations])):    \n",
    "    temp = [i for i in ortho_annotations if i['class'] == cl]\n",
    "    print(f'{cl}: {len(temp)}/{len(ortho_annotations)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35471e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### These functions implement \"non-max suppression\" to remove redundant boxes\n",
    "### which are introduced by (scenario # 1) overlap between tiles and/or\n",
    "### (scenario #2) computer vision proposals, natively.\n",
    "### They eliminate duplicates based on either IOU (intersection over union) or IOC (intersection over candidate)\n",
    "### IOU does better for similar boxes over the same object (scenario #2)\n",
    "### whereas IOC does better for clipped portions of a box overlapping the complete box (scenario #1)\n",
    "\n",
    "# sourced from Malisiewicz et al.\n",
    "# https://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/\n",
    "\n",
    "def non_max_suppression_iou(boxes, overlapThresh, probs=None):\n",
    "\n",
    "    ### this verion performs an intersect-over-union, comparing overlap to the combined areas\n",
    "    ### good for eliminating similar overlapping boxes using a generous overlap threshold\n",
    "    \n",
    "    import numpy as np\n",
    "\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # if the bounding boxes are integers, convert them to floats -- this\n",
    "    # is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "    # initialize the list of picked indexes\n",
    "    pick = []\n",
    "\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n",
    "\n",
    "    # compute the area of the bounding boxes and grab the indexes to sort\n",
    "    # (in the case that no probabilities are provided, simply sort on the\n",
    "    # areas)\n",
    "    \n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = area\n",
    "\n",
    "    # if probabilities are provided, sort on them instead\n",
    "    if probs is not None:\n",
    "        idxs = probs\n",
    "\n",
    "    # sort the indexes\n",
    "    idxs = np.argsort(idxs)\n",
    "\n",
    "    # keep looping while some indexes still remain in the indexes list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the index value\n",
    "        # to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        # find the largest (x, y) coordinates for the start of the bounding\n",
    "        # box and the smallest (x, y) coordinates for the end of the bounding\n",
    "        # box for the shared zone\n",
    "        \n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        \n",
    "        \n",
    "        # compute the width and height of the intersection box\n",
    "        #w, h = np.maximum(0, xx2 - xx1 + 1), np.maximum(0, yy2 - yy1 + 1)\n",
    "        w, h = np.maximum(0, xx2 - xx1 + 1), np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        # compute the ratio of overlap between shared area and candidates\n",
    "        overlap_ratio = (w * h) / ((area[idxs[:last]] + area[i]) - (w * h))\n",
    "        tf = np.array(overlap_ratio) > overlapThresh\n",
    "        \n",
    "        # delete all indexes from the index list that have overlap greater\n",
    "        # than the provided overlap threshold\n",
    "\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(np.array(overlap_ratio) > overlapThresh)[0])))\n",
    "        \n",
    "\n",
    "    # return the index of the bounding boxes that were picked\n",
    "    #print(f'{len(pick)} items remaining')\n",
    "    return pick\n",
    "\n",
    "def non_max_suppression_ioc(boxes, overlapThresh, probs=None):\n",
    "\n",
    "    ### this version performs an intersect-over-candidate, comparing overlap to the candidate box's area\n",
    "    ### good for eliminating similar clipped parts of the same box using a strict overlap threshold\n",
    "    \n",
    "    import numpy as np\n",
    "\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # if the bounding boxes are integers, convert them to floats -- this\n",
    "    # is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "    # initialize the list of picked indexes\n",
    "    pick = []\n",
    "\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n",
    "\n",
    "    # compute the area of the bounding boxes and grab the indexes to sort\n",
    "    # (in the case that no probabilities are provided, simply sort on the\n",
    "    # areas)\n",
    "    \n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = area\n",
    "\n",
    "    # if probabilities are provided, sort on them instead\n",
    "    if probs is not None:\n",
    "        idxs = probs\n",
    "\n",
    "    # sort the indexes\n",
    "    idxs = np.argsort(idxs)\n",
    "\n",
    "    # keep looping while some indexes still remain in the indexes list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the index value\n",
    "        # to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        # find the largest (x, y) coordinates for the start of the bounding\n",
    "        # box and the smallest (x, y) coordinates for the end of the bounding\n",
    "        # box for the shared zone\n",
    "        \n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        \n",
    "        \n",
    "        # compute the width and height of the intersection box\n",
    "        #w, h = np.maximum(0, xx2 - xx1 + 1), np.maximum(0, yy2 - yy1 + 1)\n",
    "        w, h = np.maximum(0, xx2 - xx1 + 1), np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        # compute the ratio of overlap between shared area and candidates\n",
    "        overlap_ratio = (w * h) / area[idxs[:last]]\n",
    "        tf = np.array(overlap_ratio) > overlapThresh\n",
    "        \n",
    "        # delete all indexes from the index list that have overlap greater\n",
    "        # than the provided overlap threshold\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(np.array(overlap_ratio) > overlapThresh)[0])))\n",
    "        \n",
    "\n",
    "    # return the index of the bounding boxes that were picked\n",
    "    #print(f'{len(pick)} items remaining')\n",
    "    return pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdcaaf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4193 remaining from 10208 before NMS\n",
      "2552 remaining from 10208 before NMS\n",
      "[{'box': [[6726, 2779], [6989, 2779], [6989, 3040], [6726, 3040]],\n",
      "  'class': 'Fan unk.',\n",
      "  'tile_ID': 'FCAT2APPK---318.png'},\n",
      " {'box': [[7331, 14416], [7594, 14416], [7594, 14677], [7331, 14677]],\n",
      "  'class': 'Fan unk.',\n",
      "  'tile_ID': 'FCAT2APPK---1784.png'},\n",
      " {'box': [[21939, 12619], [22202, 12619], [22202, 12880], [21939, 12880]],\n",
      "  'class': 'Fan unk.',\n",
      "  'tile_ID': 'FCAT2APPK---1569.png'},\n",
      " {'box': [[22055, 13037], [22318, 13037], [22318, 13298], [22055, 13298]],\n",
      "  'class': 'Fan unk.',\n",
      "  'tile_ID': 'FCAT2APPK---1631.png'},\n",
      " {'box': [[23259, 12948], [23522, 12948], [23522, 13209], [23259, 13209]],\n",
      "  'class': 'Fan unk.',\n",
      "  'tile_ID': 'FCAT2APPK---1633.png'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def nms_iou_on_ortho_annotations(ortho_annotations):\n",
    "    nms_detection_list=[]\n",
    "    \n",
    "    # this loop makes sure we only eliminate redundancies of the same class\n",
    "    for cl in list(set([i['class'] for i in ortho_annotations])):\n",
    "        temp = [i for i in ortho_annotations if i['class'] == cl]\n",
    "        bboxes = np.array([i['box'] for i in temp])\n",
    "        pick = non_max_suppression_iou(bboxes, 0.4)\n",
    "        for i in pick:\n",
    "            nms_detection_list.append(temp[i])\n",
    "    return nms_detection_list\n",
    "\n",
    "ortho_annotations_nms = nms_iou_on_ortho_annotations(ortho_annotations)\n",
    "print(f'{len(ortho_annotations_nms)} remaining from {len(ortho_annotations)} before NMS')\n",
    "\n",
    "def nms_ioc_on_ortho_annotations(ortho_annotations):\n",
    "    nms_detection_list=[]\n",
    "    \n",
    "    # this loop makes sure we only eliminate redundancies of the same class\n",
    "    for cl in list(set([i['class'] for i in ortho_annotations])):    \n",
    "        temp = [i for i in ortho_annotations if i['class'] == cl]\n",
    "        bboxes = np.array([i['box'] for i in temp])\n",
    "        pick = non_max_suppression_ioc(bboxes, 0.9)\n",
    "        for i in pick:\n",
    "            nms_detection_list.append(temp[i])\n",
    "    return nms_detection_list\n",
    "\n",
    "ortho_annotations_nms = nms_ioc_on_ortho_annotations(ortho_annotations)\n",
    "\n",
    "def xyxy_to_pairs(annotations2):\n",
    "    annotations = copy.deepcopy(annotations2)\n",
    "    for k, i in enumerate(annotations):\n",
    "        bounding_box = [[i['box'][0], i['box'][1]], [i['box'][2], i['box'][1]], [i['box'][2], i['box'][3]], [i['box'][0], i['box'][3]]]\n",
    "        annotations[k]['box'] = bounding_box\n",
    "    return annotations\n",
    "\n",
    "ortho_annotations_nms = xyxy_to_pairs(ortho_annotations_nms)\n",
    "print(f'{len(ortho_annotations_nms)} remaining from {len(ortho_annotations)} before NMS')\n",
    "pprint(ortho_annotations_nms[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "520a4b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts after NMS\n",
      "Fan unk.: 324/2552\n",
      "Oenocarpus bataua: 80/2552\n",
      "Astrocaryum standleyanum: 8/2552\n",
      "Attalea colenda: 12/2552\n",
      "Palm unk.: 180/2552\n",
      "Socratea exorrhiza: 76/2552\n",
      "Iriartea deltoidea: 576/2552\n",
      "Bottlebrush unk.: 8952/2552\n"
     ]
    }
   ],
   "source": [
    "print(f'Counts after NMS')\n",
    "for cl in list(set([i['class'] for i in ortho_annotations])):    \n",
    "    temp = [i for i in ortho_annotations if i['class'] == cl]\n",
    "    print(f'{cl}: {len(temp)}/{len(ortho_annotations_nms)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61ea5806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'box': [(-79.67087372308067, 0.3740214239912682),\n",
      "          (-79.67076577131166, 0.3740214239912682),\n",
      "          (-79.67076577131166, 0.3739135733102682),\n",
      "          (-79.67087372308067, 0.3739135733102682)],\n",
      "  'class': 'Fan unk.',\n",
      "  'tile_ID': 'FCAT2APPK---318.png'},\n",
      " {'box': [(-79.67062539296568, 0.36921277121426815),\n",
      "          (-79.67051744119667, 0.36921277121426815),\n",
      "          (-79.67051744119667, 0.36910492053326815),\n",
      "          (-79.67062539296568, 0.36910492053326815)],\n",
      "  'class': 'Fan unk.',\n",
      "  'tile_ID': 'FCAT2APPK---1784.png'},\n",
      " {'box': [(-79.66462934946166, 0.3699553293512682),\n",
      "          (-79.66452139769267, 0.3699553293512682),\n",
      "          (-79.66452139769267, 0.3698474786702682),\n",
      "          (-79.66462934946166, 0.3698474786702682)],\n",
      "  'class': 'Fan unk.',\n",
      "  'tile_ID': 'FCAT2APPK---1569.png'},\n",
      " {'box': [(-79.66458173575367, 0.36978260297326815),\n",
      "          (-79.66447378398468, 0.36978260297326815),\n",
      "          (-79.66447378398468, 0.36967475229226815),\n",
      "          (-79.66458173575367, 0.36967475229226815)],\n",
      "  'class': 'Fan unk.',\n",
      "  'tile_ID': 'FCAT2APPK---1631.png'},\n",
      " {'box': [(-79.66408753830167, 0.3698193796422682),\n",
      "          (-79.66397958653266, 0.3698193796422682),\n",
      "          (-79.66397958653266, 0.3697115289612682),\n",
      "          (-79.66408753830167, 0.3697115289612682)],\n",
      "  'class': 'Fan unk.',\n",
      "  'tile_ID': 'FCAT2APPK---1633.png'}]\n"
     ]
    }
   ],
   "source": [
    "# This section converts from orthomosaic annotations to global annotations\n",
    "def global_transform(box, geotransform):   \n",
    "    for k, point in enumerate(box):\n",
    "        point = geotransform * point\n",
    "        box[k] = point\n",
    "    return box\n",
    "\n",
    "def ortho_annotations_to_global(ortho_annotations2, geotransform):\n",
    "    ortho_annotations = copy.deepcopy(ortho_annotations2)\n",
    "    for k, i in enumerate(ortho_annotations):\n",
    "        ortho_annotations_nms[k]['box'] = global_transform(i['box'], geotransform)\n",
    "    return ortho_annotations\n",
    "    \n",
    "global_annotations = ortho_annotations_to_global(ortho_annotations_nms, tiling_scheme[\"transform\"])\n",
    "\n",
    "pprint(global_annotations[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f77c9c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations saved at D:/FCAT/annotations//annotations.shp\n"
     ]
    }
   ],
   "source": [
    "### During first runs I encountered an error where Fiona didn't recognize the CRS\n",
    "### some error tracing suggested that this was because my spatial packages were not\n",
    "### all installed in my conda environment using conda (some used pip)\n",
    "### and when I tried to rectify this by reinstalling in Conda the result was that\n",
    "### fiona couldn't access GDAL at all anymore\n",
    "### the solution I found was to create an environment with python 3.6, gdal 3.0.2\n",
    "### as described here: https://github.com/OSGeo/gdal/issues/6569\n",
    "### your experience may vary, if you are not using a conda environment or a windows system\n",
    "\n",
    "def shapefile_write_out(global_annotations, tiling_scheme, output_dir):\n",
    "        \n",
    "    import os, fiona\n",
    "    from collections import OrderedDict\n",
    "\n",
    "    output_path = \"{o}/annotations.shp\".format(o=output_dir)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    schema = {\n",
    "        'geometry': 'Polygon',\n",
    "        'properties': OrderedDict([\n",
    "            ('TileID', 'str'),\n",
    "            ('Class', 'str')\n",
    "        ])\n",
    "    }\n",
    "    \n",
    "    crs = tiling_scheme['spatial_reference']\n",
    "    \n",
    "    with fiona.open(output_path,\n",
    "                   'w',\n",
    "                    driver='ESRI Shapefile',\n",
    "                    crs=crs,\n",
    "                    schema=schema) as c:\n",
    "                   \n",
    "                    for num, i in enumerate(global_annotations):\n",
    "                        record = {\n",
    "                            'geometry': {'coordinates': [np.array(i['box']).astype(float)], 'type': 'Polygon'},\n",
    "                            'id': num,\n",
    "                            'properties': OrderedDict([('TileID', i['tile_ID']),\n",
    "                                                       ('Class', i['class']),\n",
    "                                                       ]),\n",
    "                            'type': 'Feature'}\n",
    "                        #print(record)\n",
    "                        c.write(record)\n",
    "    return output_path\n",
    "\n",
    "shapefile_output = shapefile_write_out(global_annotations, tiling_scheme, output_dir)\n",
    "print(f\"annotations saved at {shapefile_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e57c7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
